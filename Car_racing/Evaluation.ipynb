{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9672a372-494e-4393-8a2e-4c4581b1663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/tensordict/_pytree.py:180: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  register_pytree_node(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/tensordict/_pytree.py:199: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  register_pytree_node(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchrl/data/replay_buffers/samplers.py:34: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/tensordict/_pytree.py:180: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x156a48b30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================\n",
    "# 1) IMPORTING LIBRARIES\n",
    "# ====================================\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import torch\n",
    "import datetime\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "import gymnasium as gym\n",
    "import gymnasium.wrappers as gym_wrap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from gymnasium.spaces import Box\n",
    "from tensordict import TensorDict\n",
    "from torch import nn\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9376fe69-cebe-4650-9e80-4a552a950b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 2) GYMNASIUM WRAPPER FUNCTIONS\n",
    "# ====================================\n",
    "\n",
    "def create_skip_frame_wrapper(env, skip=4):\n",
    "    \"\"\"Skip frames wrapper to reduce computational load\"\"\"\n",
    "    class SkipFrame(gym.Wrapper):\n",
    "        def __init__(self, env, skip):\n",
    "            super().__init__(env)\n",
    "            self._skip = skip\n",
    "\n",
    "        def step(self, action):\n",
    "            total_reward = 0.0\n",
    "            for _ in range(self._skip):\n",
    "                state, reward, terminated, truncated, info = self.env.step(action)\n",
    "                total_reward += reward\n",
    "                if terminated:\n",
    "                    break\n",
    "            return state, total_reward, terminated, truncated, info\n",
    "    \n",
    "    return SkipFrame(env, skip)\n",
    "\n",
    "def create_grayscale_wrapper(env):\n",
    "    \"\"\"Convert RGB observations to grayscale\"\"\"\n",
    "    class GrayScaleObservation(gym.ObservationWrapper):\n",
    "        def __init__(self, env):\n",
    "            super().__init__(env)\n",
    "            obs_space = env.observation_space\n",
    "            h, w = obs_space.shape[:2]\n",
    "            self.observation_space = gym.spaces.Box(\n",
    "                low=0, high=255, shape=(h, w), dtype=np.uint8\n",
    "            )\n",
    "\n",
    "        def observation(self, obs):\n",
    "            return cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    return GrayScaleObservation(env)\n",
    "\n",
    "def create_resize_wrapper(env, shape=84):\n",
    "    \"\"\"Resize observations to specified shape\"\"\"\n",
    "    class ResizeObservation(gym.ObservationWrapper):\n",
    "        def __init__(self, env, shape):\n",
    "            super().__init__(env)\n",
    "            self.shape = (shape, shape)\n",
    "            self.observation_space = gym.spaces.Box(\n",
    "                low=0, high=255, shape=(shape, shape), dtype=np.uint8\n",
    "            )\n",
    "\n",
    "        def observation(self, obs):\n",
    "            return cv2.resize(obs, self.shape, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return ResizeObservation(env, shape)\n",
    "\n",
    "def create_frame_stack_wrapper(env, num_stack=4):\n",
    "    \"\"\"Stack multiple frames to provide temporal information\"\"\"\n",
    "    class FrameStack(gym.Wrapper):\n",
    "        def __init__(self, env, num_stack):\n",
    "            super().__init__(env)\n",
    "            self.num_stack = num_stack\n",
    "            self.frames = []\n",
    "            obs_shape = env.observation_space.shape\n",
    "            self.observation_space = gym.spaces.Box(\n",
    "                low=0,\n",
    "                high=255,\n",
    "                shape=(num_stack, *obs_shape),\n",
    "                dtype=np.uint8\n",
    "            )\n",
    "\n",
    "        def reset(self, **kwargs):\n",
    "            obs, info = self.env.reset(**kwargs)\n",
    "            self.frames = [obs for _ in range(self.num_stack)]\n",
    "            return self._get_observation(), info\n",
    "\n",
    "        def step(self, action):\n",
    "            obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "            self.frames.pop(0)\n",
    "            self.frames.append(obs)\n",
    "            return self._get_observation(), reward, terminated, truncated, info\n",
    "\n",
    "        def _get_observation(self):\n",
    "            return np.stack(self.frames, axis=0)\n",
    "    \n",
    "    return FrameStack(env, num_stack)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbfac35-9cd7-4aa7-b678-882c1f14361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 3) DQN NEURAL NETWORK FUNCTIONS\n",
    "# ====================================\n",
    "\n",
    "def create_dqn_network(in_dim, out_dim):\n",
    "    \"\"\"Create DQN neural network\"\"\"\n",
    "    channel_n, height, width = in_dim\n",
    "    \n",
    "    if height != 84 or width != 84:\n",
    "        raise ValueError(f\"DQN model requires input of a (84, 84)-shape. Input of a ({height, width})-shape was passed.\")\n",
    "    \n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=channel_n, out_channels=16,\n",
    "                  kernel_size=8, stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=16, out_channels=32,\n",
    "                  kernel_size=4, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(2592, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, out_dim),\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052beabf-fad7-4dd7-a309-b2f245fc1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 4) MODEL LOADING FUNCTIONS\n",
    "# ====================================\n",
    "\n",
    "def load_model_for_evaluation(model_path, state_shape, action_n):\n",
    "    \"\"\"Load a trained model for evaluation with improved state dict handling\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Create network\n",
    "    network = create_dqn_network(state_shape, action_n).float().to(device)\n",
    "    \n",
    "    # Load saved model\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    \n",
    "    loaded_model = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Extract the state dict\n",
    "    state_dict = None\n",
    "    if 'upd_model_state_dict' in loaded_model:\n",
    "        state_dict = loaded_model['upd_model_state_dict']\n",
    "    elif 'model_state_dict' in loaded_model:\n",
    "        state_dict = loaded_model['model_state_dict']\n",
    "    else:\n",
    "        # If it's just the state dict directly\n",
    "        state_dict = loaded_model\n",
    "    \n",
    "    # Handle the case where keys have \"net.\" prefix\n",
    "    if any(key.startswith('net.') for key in state_dict.keys()):\n",
    "        # Remove \"net.\" prefix from all keys\n",
    "        new_state_dict = {}\n",
    "        for key, value in state_dict.items():\n",
    "            if key.startswith('net.'):\n",
    "                new_key = key[4:]  # Remove \"net.\" prefix\n",
    "                new_state_dict[new_key] = value\n",
    "            else:\n",
    "                new_state_dict[key] = value\n",
    "        state_dict = new_state_dict\n",
    "    \n",
    "    # Load the corrected state dict\n",
    "    try:\n",
    "        network.load_state_dict(state_dict)\n",
    "        print(f\"Successfully loaded model parameters\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading state dict: {e}\")\n",
    "        print(\"Available keys in state dict:\", list(state_dict.keys()))\n",
    "        print(\"Expected keys in network:\", list(network.state_dict().keys()))\n",
    "        raise\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    network.eval()\n",
    "    \n",
    "    return network, device\n",
    "\n",
    "def take_greedy_action(network, state, device):\n",
    "    \"\"\"Take greedy action (no exploration) for evaluation\"\"\"\n",
    "    with torch.no_grad():\n",
    "        state_tensor = torch.tensor(\n",
    "            state, dtype=torch.float32, device=device\n",
    "        ).unsqueeze(0)\n",
    "        action_values = network(state_tensor)\n",
    "        action_idx = torch.argmax(action_values, axis=1).item()\n",
    "    return action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04779a26-5334-4887-bdad-67dcf39a28fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 5) ENVIRONMENT SETUP FUNCTION\n",
    "# ====================================\n",
    "\n",
    "def setup_evaluation_environment(env_name=\"CarRacing-v3\", skip_frames=4, resize_shape=84, frame_stack=4):\n",
    "    \"\"\"Setup and wrap the environment for evaluation\"\"\"\n",
    "    env = gym.make(env_name, continuous=False)\n",
    "    env = create_skip_frame_wrapper(env, skip=skip_frames)\n",
    "    env = create_grayscale_wrapper(env)\n",
    "    env = create_resize_wrapper(env, shape=resize_shape)\n",
    "    env = create_frame_stack_wrapper(env, num_stack=frame_stack)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300f503a-d754-4ed7-be5a-f3db821392b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 6) EVALUATION FUNCTIONS\n",
    "# ====================================\n",
    "\n",
    "def evaluate_single_episode(env, network, device, seed=None):\n",
    "    \"\"\"Evaluate a single episode and return the score\"\"\"\n",
    "    if seed is not None:\n",
    "        state, info = env.reset(seed=seed)\n",
    "    else:\n",
    "        state, info = env.reset()\n",
    "    \n",
    "    done = False\n",
    "    score = 0\n",
    "    steps = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = take_greedy_action(network, state, device)\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "        steps += 1\n",
    "    \n",
    "    return score, terminated, truncated, steps\n",
    "\n",
    "def evaluate_model(model_name, model_path, episodes=100, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a trained DQN model\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model for reporting\n",
    "        model_path (str): Path to the saved model file\n",
    "        episodes (int): Number of episodes to evaluate\n",
    "        verbose (bool): Whether to print progress during evaluation\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup environment\n",
    "    env = setup_evaluation_environment()\n",
    "    state, info = env.reset()\n",
    "    action_n = env.action_space.n\n",
    "    \n",
    "    # Load model\n",
    "    try:\n",
    "        network, device = load_model_for_evaluation(model_path, state.shape, action_n)\n",
    "        if verbose:\n",
    "            print(f\"Successfully loaded model: {model_name}\")\n",
    "            print(f\"Model path: {model_path}\")\n",
    "            print(f\"Device: {device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Run evaluation episodes\n",
    "    scores = []\n",
    "    completed = 0\n",
    "    total_steps = 0\n",
    "    if verbose:\n",
    "        print(f\"\\nStarting evaluation for {episodes} episodes...\")\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        score, terminated, truncated, steps = evaluate_single_episode(env, network, device)\n",
    "        \n",
    "        if not terminated and not truncated:\n",
    "            completed += 1\n",
    "        \n",
    "        scores.append(score)\n",
    "        total_steps += steps\n",
    "        \n",
    "        if verbose and (episode + 1) % 10 == 0:\n",
    "            print(f\"[{model_name}] Episode {episode + 1}: Score = {score:.2f}, Steps = {steps}\")\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    # Compute statistics\n",
    "    scores_np = np.array(scores)\n",
    "    completion_rate = (completed / episodes) * 100\n",
    "    \n",
    "    summary = {\n",
    "        \"Model\": model_name,\n",
    "        \"Episodes\": episodes,\n",
    "        \"Total steps\": total_steps,\n",
    "        \"Average steps per episode\": round(total_steps / episodes, 1),\n",
    "        \"Minimum score\": round(scores_np.min(), 2),\n",
    "        \"Maximum score\": round(scores_np.max(), 2),\n",
    "        \"Median score\": round(np.median(scores_np), 2),\n",
    "        \"Mean score\": round(scores_np.mean(), 2),\n",
    "        \"Standard deviation\": round(scores_np.std(), 2),\n",
    "        \"Scores\": scores  # Include raw scores for further analysis\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n=== Evaluation Results for {model_name} ===\")\n",
    "        for key, value in summary.items():\n",
    "            if key != \"Scores\":  # Don't print the raw scores list\n",
    "                print(f\"{key}: {value}\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def compare_models(model_configs, episodes=100):\n",
    "    \"\"\"\n",
    "    Compare multiple models\n",
    "    \n",
    "    Args:\n",
    "        model_configs (list): List of tuples (model_name, model_path)\n",
    "        episodes (int): Number of episodes to evaluate each model\n",
    "    \n",
    "    Returns:\n",
    "        list: List of evaluation summaries for each model\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Comparing {len(model_configs)} models over {episodes} episodes each...\\n\")\n",
    "    \n",
    "    for i, (model_name, model_path) in enumerate(model_configs):\n",
    "        print(f\"Evaluating model {i+1}/{len(model_configs)}: {model_name}\")\n",
    "        result = evaluate_model(model_name, model_path, episodes, verbose=True)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Print comparison summary\n",
    "    if results:\n",
    "        print(\"\\n=== COMPARISON SUMMARY ===\")\n",
    "        print(f\"{'Model':<20} {'Mean Score':<12} {'Completion':<12} {'Std Dev':<10}\")\n",
    "        print(\"-\" * 60)\n",
    "        for result in results:\n",
    "            print(f\"{result['Model']:<20} {result['Mean score']:<12} \"\n",
    "                  f\"{result['Completed episodes']:<12} {result['Standard deviation']:<10}\")\n",
    "    \n",
    "    return results   \n",
    "\n",
    "def save_evaluation_results(results, filename=\"evaluation_results.csv\"):\n",
    "    \"\"\"Save evaluation results to CSV file\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to save.\")\n",
    "        return\n",
    "    \n",
    "    # Prepare data for CSV\n",
    "    fieldnames = [\"Model\", \"Episodes\", \"Completed episodes\", \"Completed count\", \n",
    "                 \"Total steps\", \"Average steps per episode\", \"Minimum score\", \n",
    "                 \"Maximum score\", \"Median score\", \"Mean score\", \"Standard deviation\"]\n",
    "    \n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for result in results:\n",
    "            # Create a copy without the raw scores for CSV\n",
    "            csv_result = {k: v for k, v in result.items() if k != \"Scores\"}\n",
    "            writer.writerow(csv_result)\n",
    "    \n",
    "    print(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310754e0-6bdc-4372-afa3-7fc116425e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model parameters\n",
      "Successfully loaded model: DQN\n",
      "Model path: training/saved_models/DQN_740863.pt\n",
      "Device: cpu\n",
      "\n",
      "Starting evaluation for 100 episodes...\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 7) MAIN EXECUTION EXAMPLES\n",
    "# ====================================\n",
    "\n",
    "dqn_summary = evaluate_model(\"DQN\", \"training/saved_models/DQN_740863.pt\", episodes=100)       \n",
    "ddqn_summary = evaluate_model(\"DDQN\", \"training/saved_models/DDQN_743266.pt\", episodes=100)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebecd56-85e5-4855-9b68-66b91fae8c16",
   "metadata": {},
   "source": [
    "## Compare both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b797423-4113-4aa5-8f05-99d42a584e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_summary = pd.DataFrame([dqn_summary, ddqn_summary])\n",
    "df_summary = df_summary[\n",
    "    [\"Model\", \"Minimum score\", \"Maximum score\", \"Mean score\", \"Standard deviation\"]\n",
    "]\n",
    "\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336af1d6-577c-44d9-9265-fba89fc39477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_training_progress(csv_path, window_size=50):\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract episode times (skip label \"time\")\n",
    "    times = df.iloc[0, 1:].values\n",
    "    time_fmt = \"%H:%M:%S\"\n",
    "    start_time = datetime.strptime(times[0], time_fmt)\n",
    "    end_time = datetime.strptime(times[-1], time_fmt)\n",
    "    if end_time < start_time:  # handle wrap-around midnight\n",
    "        end_time = end_time.replace(day=start_time.day + 1)\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    # Extract reward values (skip label \"reward\")\n",
    "    rewards_str = df.iloc[1, 1:].values\n",
    "    rewards = pd.to_numeric(rewards_str, errors='coerce')\n",
    "    rewards_series = pd.Series(rewards)\n",
    "\n",
    "    # Compute sliding window average\n",
    "    rolling_avg = rewards_series.rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(rewards_series, label=\"Episode Reward\", alpha=0.4)\n",
    "    plt.plot(rolling_avg, label=f\"Moving Average (window={window_size})\", linewidth=2, color=\"orange\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(f\"Training Progress\\nTotal Training Time: {duration}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f9cf2-52f9-48ef-802e-42b73eb67d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_progress(\"training/logs/DQN_log_test.csv\")\n",
    "plot_training_progress(\"training/logs/DDQN_log_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54bafa-ab9c-463a-a671-a32ca544697c",
   "metadata": {},
   "source": [
    "## Run 2 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac4872-00ec-4e05-a656-6e1beaf227ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 8) CLEAN VISUAL EVALUATION FUNCTIONS\n",
    "# ====================================\n",
    "\n",
    "def setup_visual_environment(env_name=\"CarRacing-v3\", skip_frames=4, resize_shape=84, frame_stack=4):\n",
    "    \"\"\"Setup environment with human rendering for visual evaluation\"\"\"\n",
    "    env = gym.make(env_name, continuous=False, render_mode=\"human\")\n",
    "    env = create_skip_frame_wrapper(env, skip=skip_frames)\n",
    "    env = create_grayscale_wrapper(env)\n",
    "    env = create_resize_wrapper(env, shape=resize_shape)\n",
    "    env = create_frame_stack_wrapper(env, num_stack=frame_stack)\n",
    "    return env\n",
    "\n",
    "def run_visual_episode(env, network, device, episode_num, max_steps=2000, sleep_time=0.01):\n",
    "    \"\"\"Run a single episode with visual rendering\"\"\"\n",
    "    state, _ = env.reset(seed=episode_num)\n",
    "    done = False\n",
    "    steps = 0\n",
    "    score = 0\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        env.render()\n",
    "        action = take_greedy_action(network, state, device)\n",
    "        state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "        steps += 1\n",
    "        import time\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    return score, terminated, steps\n",
    "\n",
    "def run_model_visually(model_name, model_path, episodes=2):\n",
    "    \"\"\"Run visual evaluation for a single model\"\"\"\n",
    "    env = setup_visual_environment()\n",
    "    state, _ = env.reset()\n",
    "    action_n = env.action_space.n\n",
    "\n",
    "    network, device = load_model_for_evaluation(model_path, state.shape, action_n)\n",
    "\n",
    "    scores = []\n",
    "    for episode in range(episodes):\n",
    "        score, _, _ = run_visual_episode(env, network, device, episode_num=episode+1)\n",
    "        scores.append(score)\n",
    "\n",
    "    env.close()\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347795a-4a08-4143-aaad-885ad04b6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = run_model_visually(\"DQN\", \"training/saved_models/DQN_740863.pt\", episodes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e8dcdc-6022-4a2d-b89d-283b5e309da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = run_model_visually(\"DDQN\", \"training/saved_models/DDQN_743266.pt\", episodes=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
